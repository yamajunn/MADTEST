{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/chainer/chainer/tree/master/examples/vae を元にカスタマイズしたものです。  \n",
    "(注: GPU利用のみ検証)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplatform\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchainer\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gaussian_kl_divergence\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/chainer/__init__.py:82\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Alias for backward compatibility\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda  \u001b[38;5;66;03m# NOQA\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _environment_check\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchainerx\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Introduce an alias that cannot be declared at the original place due to\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# circular imports.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/chainer/_environment_check.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msystem_info\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchainer\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.distutils'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import six\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "from chainer.functions.loss.vae import gaussian_kl_divergence\n",
    "import chainer.links as L\n",
    "\n",
    "from chainer import computational_graph\n",
    "from chainer import cuda\n",
    "from chainer import optimizers\n",
    "from chainer import serializers\n",
    "from chainer import initializer\n",
    "\n",
    "import data\n",
    "from libs import gif\n",
    "\n",
    "import matplotlib\n",
    "# Disable interactive backend\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import animation as ani\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display as ipyd\n",
    "\n",
    "def print_version(libs):\n",
    "    for l in libs:\n",
    "        print(l.__name__, \":\", l.__version__)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! lsb_release -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pyenv version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"python: \", platform.python_version())\n",
    "print_version([chainer, np, matplotlib, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def show_images(x, title):\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(5, 5), dpi=100)\n",
    "    fig.suptitle(title, fontsize=8)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi.reshape(28, 28), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    \n",
    "# original images and reconstructed images\n",
    "def save_images(x, filename):\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(9, 9), dpi=100)\n",
    "    for ai, xi in zip(ax.flatten(), x):\n",
    "        ai.imshow(xi.reshape(28, 28))\n",
    "    fig.savefig(filename)\n",
    "    \n",
    "def graph_export(model):\n",
    "    with open('graph.dot', 'w') as o:\n",
    "        g = computational_graph.build_computational_graph((model.loss, ))\n",
    "        o.write(g.dump())\n",
    "    print('graph generated')\n",
    "    \n",
    "def load_mnist_dataset(test):\n",
    "    # Prepare dataset\n",
    "    print('load MNIST dataset')\n",
    "    mnist = data.load_mnist_data()\n",
    "    mnist['data'] = mnist['data'].astype(np.float32)\n",
    "    mnist['data'] /= 255\n",
    "    mnist['target'] = mnist['target'].astype(np.int32)\n",
    "\n",
    "    if test:\n",
    "        mnist['data'] = mnist['data'][0:100]\n",
    "        mnist['target'] = mnist['target'][0:100]\n",
    "        N = 30\n",
    "    else:\n",
    "        N = 60000\n",
    "\n",
    "    x_train, x_test = np.split(mnist['data'],   [N])\n",
    "    y_train, y_test = np.split(mnist['target'], [N])\n",
    "    N_train = y_train.size\n",
    "    N_test = y_test.size\n",
    "    return x_train, x_test, y_train, y_test, N, N_test, N_train\n",
    "\n",
    "\n",
    "def montage(images):\n",
    "    if isinstance(images, list):\n",
    "        images = np.array(images)\n",
    "    img_h = images.shape[1]\n",
    "    img_w = images.shape[2]\n",
    "    n_plots = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "    if len(images.shape) == 4 and images.shape[3] == 3:\n",
    "        m = np.ones(\n",
    "            (images.shape[1] * n_plots + n_plots + 1,\n",
    "             images.shape[2] * n_plots + n_plots + 1, 3)) * 0.5\n",
    "    else:\n",
    "        m = np.ones(\n",
    "            (images.shape[1] * n_plots + n_plots + 1,\n",
    "             images.shape[2] * n_plots + n_plots + 1)) * 0.5\n",
    "    for i in range(n_plots):\n",
    "        for j in range(n_plots):\n",
    "            this_filter = i * n_plots + j\n",
    "            if this_filter < images.shape[0]:\n",
    "                this_img = images[this_filter]\n",
    "                m[1 + i + i * img_h:1 + i + (i + 1) * img_h,\n",
    "                  1 + j + j * img_w:1 + j + (j + 1) * img_w] = this_img\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://jmetzen.github.io/2015-11-27/vae.html\n",
    "class Xavier(initializer.Initializer):\n",
    "    \"\"\"\n",
    "    Xavier initializaer \n",
    "    Reference: \n",
    "    * https://jmetzen.github.io/2015-11-27/vae.html\n",
    "    * https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "    \"\"\"\n",
    "    def __init__(self, fan_in, fan_out, constant=1, dtype=None):\n",
    "        self.fan_in = fan_in\n",
    "        self.fan_out = fan_out\n",
    "        self.high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "        self.low = -self.high\n",
    "        super(Xavier, self).__init__(dtype)\n",
    "\n",
    "    def __call__(self, array):\n",
    "        xp = cuda.get_array_module(array)\n",
    "        args = {'low': self.low, 'high': self.high, 'size': array.shape}\n",
    "        if xp is not np:\n",
    "            # Only CuPy supports dtype option\n",
    "            if self.dtype == np.float32 or self.dtype == np.float16:\n",
    "                # float16 is not supported in cuRAND\n",
    "                args['dtype'] = np.float32\n",
    "        array[...] = xp.random.uniform(**args)\n",
    "\n",
    "\n",
    "# Original implementation: https://github.com/chainer/chainer/tree/master/examples/vae\n",
    "class VAE(chainer.Chain):\n",
    "    \"\"\"Variational AutoEncoder\"\"\"\n",
    "\n",
    "    def __init__(self, n_in, n_latent, n_h, act_func=F.tanh):\n",
    "        super(VAE, self).__init__()\n",
    "        self.act_func = act_func\n",
    "        with self.init_scope():\n",
    "            # encoder\n",
    "            self.le1        = L.Linear(n_in, n_h,      initialW=Xavier(n_in, n_h))\n",
    "            self.le2        = L.Linear(n_h,  n_h,      initialW=Xavier(n_h, n_h))\n",
    "            self.le3_mu     = L.Linear(n_h,  n_latent, initialW=Xavier(n_h,  n_latent))\n",
    "            self.le3_ln_var = L.Linear(n_h,  n_latent, initialW=Xavier(n_h,  n_latent))\n",
    "            \n",
    "            # decoder\n",
    "            self.ld1 = L.Linear(n_latent, n_h, initialW=Xavier(n_latent, n_h))\n",
    "            self.ld2 = L.Linear(n_h,      n_h, initialW=Xavier(n_h, n_h))\n",
    "            self.ld3 = L.Linear(n_h,      n_in,initialW=Xavier(n_h, n_in))\n",
    "\n",
    "    def __call__(self, x, sigmoid=True):\n",
    "        \"\"\" AutoEncoder \"\"\"\n",
    "        return self.decode(self.encode(x)[0], sigmoid)\n",
    "\n",
    "    def encode(self, x):\n",
    "        if type(x) != chainer.variable.Variable:\n",
    "            x = chainer.Variable(x)\n",
    "        x.name = \"x\"\n",
    "        h1 = self.act_func(self.le1(x))\n",
    "        h1.name = \"enc_h1\"\n",
    "        h2 = self.act_func(self.le2(h1))\n",
    "        h2.name = \"enc_h2\"\n",
    "        mu = self.le3_mu(h2)\n",
    "        mu.name = \"z_mu\"\n",
    "        ln_var = self.le3_ln_var(h2)  # ln_var = log(sigma**2)\n",
    "        ln_var.name = \"z_ln_var\"\n",
    "        return mu, ln_var\n",
    "\n",
    "    def decode(self, z, sigmoid=True):\n",
    "        h1 = self.act_func(self.ld1(z))\n",
    "        h1.name = \"dec_h1\"\n",
    "        h2 = self.act_func(self.ld2(h1))\n",
    "        h2.name = \"dec_h2\"\n",
    "        h3 = self.ld3(h2)\n",
    "        h3.name = \"dec_h3\"\n",
    "        if sigmoid:\n",
    "            return F.sigmoid(h3)\n",
    "        else:\n",
    "            return h3\n",
    "\n",
    "    def get_loss_func(self, C=1.0, k=1):\n",
    "        \"\"\"Get loss function of VAE.\n",
    "\n",
    "        The loss value is equal to ELBO (Evidence Lower Bound)\n",
    "        multiplied by -1.\n",
    "\n",
    "        Args:\n",
    "            C (int): Usually this is 1.0. Can be changed to control the\n",
    "                second term of ELBO bound, which works as regularization.\n",
    "            k (int): Number of Monte Carlo samples used in encoded vector.\n",
    "        \"\"\"\n",
    "        def lf(x):\n",
    "            mu, ln_var = self.encode(x)\n",
    "            batchsize = len(mu.data)\n",
    "            # reconstruction loss\n",
    "            rec_loss = 0\n",
    "            for l in six.moves.range(k):\n",
    "                z = F.gaussian(mu, ln_var)\n",
    "                z.name = \"z\"\n",
    "                rec_loss += F.bernoulli_nll(x, self.decode(z, sigmoid=False)) / (k * batchsize)\n",
    "            self.rec_loss = rec_loss\n",
    "            self.rec_loss.name = \"reconstruction error\"\n",
    "            self.latent_loss = C * gaussian_kl_divergence(mu, ln_var) / batchsize\n",
    "            self.latent_loss.name = \"latent loss\"\n",
    "            self.loss = self.rec_loss + self.latent_loss\n",
    "            self.loss.name = \"loss\"\n",
    "            return self.loss\n",
    "        return lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# settings\n",
    "initmodel = ''\n",
    "resume = ''\n",
    "gpu = 0\n",
    "n_epoch = 100\n",
    "n_latent = 20\n",
    "# n_latent = 2\n",
    "batchsize = 100\n",
    "\n",
    "test = False\n",
    "graph_gen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "x_train, x_test, y_train, y_test, N, N_test, N_train = load_mnist_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare VAE model\n",
    "model = VAE(784, n_latent, n_h=500, act_func=F.softplus)\n",
    "\n",
    "if gpu >= 0:\n",
    "    cuda.get_device_from_id(gpu).use()\n",
    "    model.to_gpu()\n",
    "xp = np if gpu < 0 else cuda.cupy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "# Init/Resume\n",
    "if initmodel:\n",
    "    print('Load model from', initmodel)\n",
    "    serializers.load_npz(initmodel, model)\n",
    "if resume:\n",
    "    print('Load optimizer state from', resume)\n",
    "    serializers.load_npz(resume, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Learning loop\n",
    "loss_list_train = []\n",
    "loss_list_test = []\n",
    "\n",
    "for epoch in six.moves.range(1, n_epoch + 1):\n",
    "    print('epoch', epoch)\n",
    "\n",
    "    # training\n",
    "    perm = np.random.permutation(N)\n",
    "    sum_loss = 0       # total loss\n",
    "    sum_rec_loss = 0   # reconstruction loss\n",
    "    for i in six.moves.range(0, N, batchsize):\n",
    "        x = chainer.Variable(xp.asarray(x_train[perm[i:i + batchsize]]))\n",
    "        optimizer.update(model.get_loss_func(), x)\n",
    "        if epoch == 1 and i == 0 and graph_gen:\n",
    "            graph_export(model)\n",
    "\n",
    "        sum_loss += float(model.loss.data) * len(x.data)\n",
    "        sum_rec_loss += float(model.rec_loss.data) * len(x.data)\n",
    "    loss_train = sum_loss / N\n",
    "    print('train mean loss={}, mean reconstruction loss={}'.format(sum_loss / N, sum_rec_loss / N))\n",
    "\n",
    "    # evaluation\n",
    "    sum_loss = 0\n",
    "    sum_rec_loss = 0\n",
    "    with chainer.no_backprop_mode():\n",
    "        for i in six.moves.range(0, N_test, batchsize):\n",
    "            x = chainer.Variable(xp.asarray(x_test[i:i + batchsize]))\n",
    "            loss_func = model.get_loss_func(k=10)\n",
    "            loss_func(x)\n",
    "            sum_loss += float(model.loss.data) * len(x.data)\n",
    "            sum_rec_loss += float(model.rec_loss.data) * len(x.data)\n",
    "            del model.loss\n",
    "    print('test  mean loss={}, mean reconstruction loss={}'\n",
    "          .format(sum_loss / N_test, sum_rec_loss / N_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and the optimizer\n",
    "print('save the model')\n",
    "serializers.save_npz('mlp_{}.model'.format(n_latent), model)\n",
    "print('save the optimizer')\n",
    "serializers.save_npz('mlp_{}.state'.format(n_latent), optimizer)\n",
    "\n",
    "# model.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_sample = chainer.Variable(x_test[:10].astype(np.float32))\n",
    "x_sample.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 復元前と後の画像の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def convert(data_gpu):\n",
    "    data_gpu = data_gpu*255\n",
    "    data_gpu = data_gpu.data.astype(xp.int32)\n",
    "    return chainer.cuda.to_cpu(data_gpu)\n",
    "\n",
    "def draw_result(model, x, n=10):\n",
    "    assert n > 0\n",
    "    x_sample = x[:n+1]\n",
    "    x_sample = chainer.Variable(x_sample.astype(np.float32))\n",
    "    x_sample.to_gpu()\n",
    "    x_reconstruct = model(x_sample)\n",
    "    \n",
    "\n",
    "    x_sample = convert(x_sample)\n",
    "    x_reconstruct = convert(x_reconstruct)\n",
    "    \n",
    "    plt.figure(figsize=(8, n*3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(n, 2, 2*i + 1)\n",
    "        plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=255, cmap=\"gray\")\n",
    "        plt.title(\"Input image\")\n",
    "        plt.xticks([]);plt.yticks([])\n",
    "        \n",
    "        plt.subplot(n, 2, 2*i + 2)\n",
    "        plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=255, cmap=\"gray\")\n",
    "        plt.title(\"Reconstruction image\")\n",
    "        plt.xticks([]);plt.yticks([])\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# OriginalとReconstrauctionの比較\n",
    "draw_result(model, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0〜9までのzを取り出してを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 100\n",
    "x_sample, y_sample = x_test[:n_sample], y_test[:n_sample]\n",
    "\n",
    "idx_list = []\n",
    "for i in range(10):\n",
    "    idx = y_sample==i\n",
    "    #np.arange(len(idx))\n",
    "    idx_list.append(np.min(np.arange(n_sample)[idx]))\n",
    "\n",
    "x_sample, y_sample = x_test[idx_list], y_test[idx_list]\n",
    "z_mu = model.encode(chainer.cuda.to_gpu(x_sample))[0]\n",
    "x_reconstract = model.decode(z_mu)\n",
    "#x_reconstract = model(chainer.cuda.to_gpu(x_sample))\n",
    "x_reconstract.to_cpu()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "for i, x_gen in enumerate(x_reconstract.data):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.imshow(x_gen.reshape(28, 28), vmin=0, vmax=1, cmap=\"gray\")\n",
    "    plt.title(\"Reconstract data: {}\".format(i))\n",
    "    plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "end   = 9\n",
    "n_image = 81\n",
    "n_row = int(np.ceil(np.sqrt(n_image)))\n",
    "imgs = []\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "for i, t in enumerate(np.linspace(0, 1, n_image)):\n",
    "    print(i, end=\", \")\n",
    "    z_tmp = (1-t)*z_mu[start] + t*z_mu[end]\n",
    "    x_gen = model.decode(z_tmp.reshape(1, n_latent))\n",
    "    \n",
    "    plt.subplot(n_row, n_row, i+1)\n",
    "    im = convert(x_gen).reshape(28, 28)\n",
    "    plt.imshow(im, vmin=0, vmax=255, cmap=\"gray\")\n",
    "    imgs.append(im)\n",
    "    plt.xticks([]);plt.yticks([])\n",
    "    plt.title(\"t={0:.3f}\".format(t))\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ImageMagikのインストール\n",
    "アニメーション作成に必要です\n",
    "```\n",
    "sudo apt-get install imagemagick\n",
    "sudo apt-get install python-pythonmagick\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(nframe):\n",
    "    print(\"\\r nframe={}, n_image={}\".format(nframe, n_image), end=\"\")\n",
    "    plt.imshow(imgs[nframe], cmap=\"gray\")\n",
    "    plt.xticks([]);plt.yticks([])\n",
    "    plt.title(\"t={}\".format(nframe))\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "anim = ani.FuncAnimation(fig, animate, frames=n_image)\n",
    "anim.save('vae_{}to{}.gif'.format(start, end), writer='imagemagick', fps=12, dpi=64)\n",
    "\n",
    "#anim.save('vae_{}to{}.mp4'.format(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyd.Image(url='vae_{}to{}.gif?i={}'.format(start, end, np.random.rand()), height=300, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全ての数字を対象にアニメーション作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(z_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_image = 40\n",
    "imgs = []\n",
    "for i, t in enumerate(np.r_[np.linspace(0, 1, n_image), np.linspace(0, 1, n_image)[::-1]]):\n",
    "    tmp_imgs = []\n",
    "    print(\"\\r i={}, n_image={}\".format(i, n_image), end=\"\")\n",
    "    for start in range(10):\n",
    "        for end in range(10):\n",
    "            n_row = int(np.ceil(np.sqrt(n_image)))\n",
    "\n",
    "            z_tmp = (1-t)*z_mu[start] + t*z_mu[end]\n",
    "            x_gen = model.decode(z_tmp.reshape(1, n_latent))\n",
    "            tmp_imgs.append(convert(x_gen).reshape(28, 28))\n",
    "    imgs.append(montage(tmp_imgs))\n",
    "\n",
    "def animate(nframe):\n",
    "    print(nframe, end=', ')\n",
    "    plt.imshow(imgs[nframe], cmap=\"gray\")\n",
    "    plt.xticks([]);plt.yticks([])\n",
    "    plt.title(\"t={}\".format(nframe))\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "anim = ani.FuncAnimation(fig, animate, frames=n_image*2)\n",
    "anim.save('vae_all_{}to{}.gif'.format(start, end), writer='imagemagick', fps=10, dpi=64)\n",
    "plt.close()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipyd.Image(url='vae_all_{}to{}.gif?i={}'.format(start, end, np.random.rand()), height=400, width=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2次元にプロットする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のコードは`n_latent=2`で学習したのち実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean(z_mu, y_sample, num):\n",
    "    for i in range(10):\n",
    "        idx = y_sample==num\n",
    "        return np.mean(z_mu[idx], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_sample = 5000\n",
    "x_sample, y_sample = x_test[:n_sample], y_test[:n_sample]\n",
    "\n",
    "z_mu = model.encode(chainer.cuda.to_gpu(x_sample))[0]\n",
    "z_mu.to_cpu()\n",
    "z_mu = z_mu.data\n",
    "\n",
    "plt.figure(figsize=(10, 8)) \n",
    "plt.scatter(z_mu[:, 0], z_mu[:, 1], c=y_sample, cmap=\"rainbow\", alpha=0.6)\n",
    "for i in range(10):\n",
    "    m = get_mean(z_mu, y_sample, i)\n",
    "    plt.text(m[0], m[1], \"{}\".format(i), fontsize=20)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_sample = 100\n",
    "x_sample, y_sample = x_test[:n_sample], y_test[:n_sample]\n",
    "\n",
    "idx_list = []\n",
    "for i in range(10):\n",
    "    idx = y_sample==i\n",
    "    #np.arange(len(idx))\n",
    "    idx_list.append(np.min(np.arange(n_sample)[idx]))\n",
    "\n",
    "x_sample, y_sample = x_test[idx_list], y_test[idx_list]\n",
    "z_mu = model.encode(chainer.cuda.to_gpu(x_sample))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end   = 7\n",
    "n_image = 81\n",
    "n_row = int(np.ceil(np.sqrt(n_image)))\n",
    "imgs = []\n",
    "\n",
    "plt.figure(figsize=(14,14))\n",
    "for i, t in enumerate(np.linspace(0, 1, n_image)):\n",
    "    print(i, end=\", \")\n",
    "    z_tmp = (1-t)*z_mu[start] + t*z_mu[end]\n",
    "    x_gen = model.decode(z_tmp.reshape(1, n_latent))\n",
    "    \n",
    "    plt.subplot(n_row, n_row, i+1)\n",
    "    im = convert(x_gen).reshape(28, 28)\n",
    "    plt.imshow(im, vmin=0, vmax=255, cmap=\"gray\")\n",
    "    imgs.append(im)\n",
    "    plt.xticks([]);plt.yticks([])\n",
    "    plt.title(\"t={0:.3f}\".format(t))\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(nframe):\n",
    "    print(\"\\r nframe={}, n_image={}\".format(nframe, n_image), end=\"\")\n",
    "    plt.imshow(imgs[nframe], cmap=\"gray\")\n",
    "    plt.xticks([]);plt.yticks([])\n",
    "    plt.title(\"t={}\".format(nframe))\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "anim = ani.FuncAnimation(fig, animate, frames=n_image)\n",
    "anim.save('vae_{}to{}_dim{}.gif'.format(start, end, n_latent), writer='imagemagick', fps=12, dpi=64)\n",
    "\n",
    "#anim.save('vae_{}to{}.mp4'.format(start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# z to Xの可視化\n",
    "\n",
    "nx = ny = 25\n",
    "x_values = xp.linspace(-2, 2, nx)\n",
    "y_values = xp.linspace(-2, 2, ny)\n",
    "\n",
    "cnt = 0\n",
    "canvas = xp.empty((28*ny, 28*nx))\n",
    "for i, yi in enumerate(x_values):\n",
    "    for j, xi in enumerate(y_values):\n",
    "        print(\"\\r cnt={}/{}\".format(cnt, nx*ny), end=\"\"); cnt += 1\n",
    "        # draw images from randomly sampled z\n",
    "        z = chainer.Variable(xp.array([[xi, yi]], dtype=xp.float32)) \n",
    "        x_mean = model.decode(z)\n",
    "        canvas[(nx-i-1)*28:(nx-i)*28, j*28:(j+1)*28] = (x_mean*255).data.astype(xp.int32).reshape(28,28)\n",
    "        \n",
    "# GPUのデータをCPUに移す\n",
    "canvas_cpu = chainer.cuda.to_cpu(canvas)\n",
    "\n",
    "plt.figure(figsize=(10, 15))        \n",
    "Xi, Yi = xp.meshgrid(x_values, y_values)\n",
    "plt.imshow(canvas_cpu, origin=\"upper\", cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"mapping.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グラフ構造の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphviz is necessary.\n",
    "!dot -Tpng graph.dot -o vae_graph.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"vae_graph.png?a=3\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
